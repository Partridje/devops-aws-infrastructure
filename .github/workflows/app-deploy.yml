name: Deploy Application

# Application deployment is MANUAL ONLY
# Infrastructure must be deployed first using terraform-apply workflow
on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to (infrastructure must exist)'
        required: true
        type: choice
        options:
          - dev
          - prod
      image_tag:
        description: 'Docker image tag (default: latest commit SHA)'
        required: false
        type: string

permissions:
  id-token: write  # Required for OIDC
  contents: read
  packages: write

env:
  AWS_REGION: eu-north-1
  PROJECT_NAME: demo-app

jobs:
  # First, verify infrastructure exists
  verify-infrastructure:
    name: Verify Infrastructure
    runs-on: ubuntu-latest
    outputs:
      ecr_repository: ${{ steps.check-infra.outputs.ecr_repository }}
      asg_name: ${{ steps.check-infra.outputs.asg_name }}
      alb_url: ${{ steps.check-infra.outputs.alb_url }}

    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Check infrastructure exists
        id: check-infra
        run: |
          ENV="${{ github.event.inputs.environment }}"

          echo "Checking infrastructure for environment: ${ENV}"

          # Check ECR Repository
          ECR_REPO="${{ env.PROJECT_NAME }}-${ENV}-app"
          if aws ecr describe-repositories --repository-names "${ECR_REPO}" --region ${{ env.AWS_REGION }} > /dev/null 2>&1; then
            echo "✓ ECR repository exists: ${ECR_REPO}"
            ECR_URI=$(aws ecr describe-repositories --repository-names "${ECR_REPO}" --region ${{ env.AWS_REGION }} --query 'repositories[0].repositoryUri' --output text)
            echo "ecr_repository=${ECR_URI}" >> $GITHUB_OUTPUT
          else
            echo "::error::ECR repository not found: ${ECR_REPO}"
            echo "Please run terraform-apply workflow first to create infrastructure"
            exit 1
          fi

          # Check Auto Scaling Group (search by name prefix)
          ASG_NAME=$(aws autoscaling describe-auto-scaling-groups \
            --query "AutoScalingGroups[?starts_with(AutoScalingGroupName, '${{ env.PROJECT_NAME }}-${ENV}-')].AutoScalingGroupName" \
            --output text | head -n1)

          if [ -z "${ASG_NAME}" ]; then
            echo "::error::Auto Scaling Group not found for environment: ${ENV}"
            echo "Please run terraform-apply workflow first to create infrastructure"
            exit 1
          fi

          echo "✓ Auto Scaling Group exists: ${ASG_NAME}"
          echo "asg_name=${ASG_NAME}" >> $GITHUB_OUTPUT

          # Check Application Load Balancer (search by name prefix)
          ALB_DNS=$(aws elbv2 describe-load-balancers \
            --query "LoadBalancers[?starts_with(LoadBalancerName, '${{ env.PROJECT_NAME }}-${ENV}-')].DNSName" \
            --output text | head -n1)

          if [ -z "${ALB_DNS}" ]; then
            echo "::error::Application Load Balancer not found for environment: ${ENV}"
            echo "Please run terraform-apply workflow first to create infrastructure"
            exit 1
          fi

          echo "✓ Load Balancer exists: ${ALB_DNS}"

          # Set ALB URL based on environment
          if [ "${ENV}" == "prod" ]; then
            echo "alb_url=https://${ALB_DNS}" >> $GITHUB_OUTPUT
          else
            echo "alb_url=http://${ALB_DNS}" >> $GITHUB_OUTPUT
          fi

          echo ""
          echo "Infrastructure verification completed successfully!"
          echo "ECR: ${ECR_URI}"
          echo "ASG: ${ASG_NAME}"
          echo "ALB: ${ALB_DNS}"

  build:
    name: Build and Push Docker Image
    needs: verify-infrastructure
    runs-on: ubuntu-latest
    outputs:
      image: ${{ steps.meta.outputs.image }}

    steps:
      #####################################
      # Checkout Code
      #####################################
      - name: Checkout repository
        uses: actions/checkout@v4

      #####################################
      # Setup Docker Buildx
      #####################################
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      #####################################
      # Configure AWS Credentials
      #####################################
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      #####################################
      # Login to ECR
      #####################################
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      #####################################
      # Generate Image Tags
      #####################################
      - name: Generate image tags
        id: meta
        run: |
          # Use ECR repository from infrastructure verification
          ECR_REPO="${{ needs.verify-infrastructure.outputs.ecr_repository }}"
          ECR_REPO_NAME=$(echo "${ECR_REPO}" | cut -d'/' -f2)

          # Use provided image tag or default to commit SHA
          if [ -n "${{ github.event.inputs.image_tag }}" ]; then
            IMAGE_TAG="${{ github.event.inputs.image_tag }}"
          else
            IMAGE_TAG="${{ github.sha }}"
          fi

          # Build tags (only commit SHA, no 'latest')
          TAGS="${ECR_REPO}:${IMAGE_TAG}"

          # Check if image already exists in ECR
          if aws ecr describe-images \
            --repository-name "${ECR_REPO_NAME}" \
            --image-ids imageTag="${IMAGE_TAG}" \
            --region ${{ env.AWS_REGION }} > /dev/null 2>&1; then

            echo "✓ Image already exists in ECR: ${ECR_REPO}:${IMAGE_TAG}"
            echo "image_exists=true" >> $GITHUB_OUTPUT
          else
            echo "Image not found in ECR, will build and push"
            echo "image_exists=false" >> $GITHUB_OUTPUT
          fi

          echo "tags=${TAGS}" >> $GITHUB_OUTPUT
          echo "image=${ECR_REPO}:${IMAGE_TAG}" >> $GITHUB_OUTPUT

          echo "Docker image will be tagged as:"
          echo "  - ${ECR_REPO}:${IMAGE_TAG}"

      #####################################
      # Build Docker Image
      #####################################
      - name: Build Docker image
        if: steps.meta.outputs.image_exists != 'true'
        uses: docker/build-push-action@v5
        with:
          context: ./app
          push: false
          load: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          labels: |
            org.opencontainers.image.source=${{ github.repositoryUrl }}
            org.opencontainers.image.revision=${{ github.sha }}

      #####################################
      # Scan Docker Image
      #####################################
      - name: Run Trivy vulnerability scanner
        if: steps.meta.outputs.image_exists != 'true'
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.meta.outputs.image }}
          format: 'sarif'
          output: 'trivy-results.sarif'
          severity: 'CRITICAL,HIGH'
        continue-on-error: true

      - name: Upload Trivy results
        if: steps.meta.outputs.image_exists != 'true'
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: 'trivy-results.sarif'
        continue-on-error: true

      #####################################
      # Test Docker Image
      #####################################
      - name: Test Docker image
        if: steps.meta.outputs.image_exists != 'true'
        run: |
          # Start container
          docker run -d --name test-app \
            -p 5001:5001 \
            -e DB_HOST=localhost \
            -e ENVIRONMENT=test \
            ${{ steps.meta.outputs.image }}

          # Wait for app to start
          sleep 10

          # Test health endpoint
          curl -f http://localhost:5001/health || exit 1

          # Stop container
          docker stop test-app

      #####################################
      # Push to ECR
      #####################################
      - name: Push Docker image to ECR
        if: steps.meta.outputs.image_exists != 'true'
        uses: docker/build-push-action@v5
        with:
          context: ./app
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          labels: |
            org.opencontainers.image.source=${{ github.repositoryUrl }}
            org.opencontainers.image.revision=${{ github.sha }}
            environment=${{ github.event.inputs.environment }}

      #####################################
      # Output Image Info
      #####################################
      - name: Image Info
        run: |
          echo "✓ Image pushed successfully!"
          echo "Image: ${{ steps.meta.outputs.image }}"
          echo "Environment: ${{ github.event.inputs.environment }}"
          echo "image=${{ steps.meta.outputs.image }}" >> $GITHUB_OUTPUT

  deploy:
    name: Deploy to ${{ github.event.inputs.environment }}
    needs: [verify-infrastructure, build]
    runs-on: ubuntu-latest
    environment:
      name: ${{ github.event.inputs.environment }}

    steps:
      #####################################
      # Checkout Code
      #####################################
      - name: Checkout repository
        uses: actions/checkout@v4

      #####################################
      # Configure AWS Credentials
      #####################################
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      #####################################
      # Update SSM Parameter with new app version
      #####################################
      - name: Update SSM Parameter
        run: |
          ENV="${{ github.event.inputs.environment }}"
          IMAGE_TAG="${{ needs.build.outputs.image }}"
          IMAGE_TAG_ONLY=$(echo "$IMAGE_TAG" | cut -d':' -f2)

          # SSM Parameter name pattern
          SSM_PARAM="/${{ env.PROJECT_NAME }}/${ENV}/app/version"

          echo "Updating SSM Parameter: ${SSM_PARAM}"
          echo "New version: ${IMAGE_TAG_ONLY}"

          # Update SSM Parameter
          aws ssm put-parameter \
            --name "${SSM_PARAM}" \
            --value "${IMAGE_TAG_ONLY}" \
            --type String \
            --overwrite \
            --region ${{ env.AWS_REGION }}

          echo "✓ SSM Parameter updated successfully"

      #####################################
      # Deploy to existing instances via SSM Run Command
      #####################################
      - name: Deploy to existing instances
        run: |
          ASG_NAME="${{ needs.verify-infrastructure.outputs.asg_name }}"

          echo "Deploying application to existing EC2 instances via SSM Run Command..."

          # Get list of instance IDs from ASG
          INSTANCE_IDS=$(aws autoscaling describe-auto-scaling-groups \
            --auto-scaling-group-names "${ASG_NAME}" \
            --query "AutoScalingGroups[0].Instances[?HealthStatus=='Healthy' && LifecycleState=='InService'].InstanceId" \
            --output text)

          if [ -z "$INSTANCE_IDS" ]; then
            echo "No healthy instances found in ASG. Skipping deployment to existing instances."
          else
            echo "Found instances: $INSTANCE_IDS"

            # Run deployment script on all instances
            COMMAND_ID=$(aws ssm send-command \
              --document-name "AWS-RunShellScript" \
              --instance-ids $INSTANCE_IDS \
              --parameters 'commands=["/usr/local/bin/deploy-app.sh"]' \
              --timeout-seconds 600 \
              --region ${{ env.AWS_REGION }} \
              --query "Command.CommandId" \
              --output text)

            echo "SSM Run Command initiated: ${COMMAND_ID}"
            echo "Waiting for deployment to complete..."

            # Wait for command to complete on all instances
            for instance in $INSTANCE_IDS; do
              aws ssm wait command-executed \
                --command-id "${COMMAND_ID}" \
                --instance-id "$instance" \
                --region ${{ env.AWS_REGION }} \
                || echo "WARNING: Instance $instance may have failed. Check SSM command output."
            done

            echo "✓ Deployment to existing instances completed"
          fi

      #####################################
      # Check for concurrent deployments
      #####################################
      - name: Check for concurrent deployments
        run: |
          ASG_NAME="${{ needs.verify-infrastructure.outputs.asg_name }}"

          echo "Checking for active instance refresh..."

          # Check if there's an active instance refresh
          ACTIVE_REFRESH=$(aws autoscaling describe-instance-refreshes \
            --auto-scaling-group-name "${ASG_NAME}" \
            --query "InstanceRefreshes[?Status=='InProgress' || Status=='Pending'].Status" \
            --output text \
            --region ${{ env.AWS_REGION }})

          if [ -n "$ACTIVE_REFRESH" ]; then
            echo "::error::Instance Refresh is already in progress for ASG: ${ASG_NAME}"
            echo "::error::Please wait for the current refresh to complete before starting a new deployment"
            echo "::error::This prevents concurrent deployment conflicts"
            exit 1
          fi

          echo "✓ No active instance refresh found. Safe to proceed."

      #####################################
      # Trigger Instance Refresh (for new instances)
      #####################################
      - name: Start instance refresh
        run: |
          ASG_NAME="${{ needs.verify-infrastructure.outputs.asg_name }}"
          ENV="${{ github.event.inputs.environment }}"

          echo "Starting instance refresh for ASG: ${ASG_NAME}"

          # Use different strategies for dev vs prod
          if [ "${ENV}" == "prod" ]; then
            # Production: Blue-Green deployment with checkpoints
            aws autoscaling start-instance-refresh \
              --auto-scaling-group-name "${ASG_NAME}" \
              --preferences '{"MinHealthyPercentage": 100, "InstanceWarmup": 300, "CheckpointPercentages": [50], "CheckpointDelay": 300}'
          else
            # Development: Faster rolling update
            aws autoscaling start-instance-refresh \
              --auto-scaling-group-name "${ASG_NAME}" \
              --preferences '{"MinHealthyPercentage": 90, "InstanceWarmup": 300}'
          fi

      - name: Wait for instance refresh
        timeout-minutes: 30
        run: |
          ASG_NAME="${{ needs.verify-infrastructure.outputs.asg_name }}"

          echo "Waiting for instance refresh to complete..."

          while true; do
            STATUS=$(aws autoscaling describe-instance-refreshes \
              --auto-scaling-group-name "${ASG_NAME}" \
              --query "InstanceRefreshes[0].Status" \
              --output text)

            PERCENT=$(aws autoscaling describe-instance-refreshes \
              --auto-scaling-group-name "${ASG_NAME}" \
              --query "InstanceRefreshes[0].PercentageComplete" \
              --output text)

            echo "Refresh status: ${STATUS} (${PERCENT}% complete)"

            if [ "${STATUS}" == "Successful" ]; then
              echo "✓ Instance refresh completed successfully"
              break
            elif [ "${STATUS}" == "Failed" ] || [ "${STATUS}" == "Cancelled" ]; then
              echo "::error::Instance refresh failed with status: ${STATUS}"
              exit 1
            fi

            sleep 30
          done

      #####################################
      # Smoke Tests
      #####################################
      - name: Run smoke tests
        run: |
          ALB_URL="${{ needs.verify-infrastructure.outputs.alb_url }}"

          echo "Running smoke tests against ${ALB_URL}"

          # Wait for instances to be healthy
          sleep 60

          # Test health endpoint
          echo "Testing /health..."
          curl -f "${ALB_URL}/health" || exit 1

          # Test database connectivity
          echo "Testing /db..."
          curl -f "${ALB_URL}/db" || exit 1

          # Test main page
          echo "Testing /..."
          curl -f "${ALB_URL}/" || exit 1

          echo "✓ All smoke tests passed!"

      #####################################
      # Rollback on Failure
      #####################################
      - name: Rollback on failure
        if: failure()
        run: |
          ASG_NAME="${{ needs.verify-infrastructure.outputs.asg_name }}"

          echo "::error::Deployment failed!"
          echo "Cancelling instance refresh..."

          aws autoscaling cancel-instance-refresh \
            --auto-scaling-group-name "${ASG_NAME}" \
            || true

          echo "Consider rolling back to previous version"

      #####################################
      # Deployment Summary
      #####################################
      - name: Deployment summary
        if: success()
        run: |
          echo "=========================================="
          echo "Deployment Completed Successfully!"
          echo "=========================================="
          echo "Environment: ${{ github.event.inputs.environment }}"
          echo "Image: ${{ needs.build.outputs.image }}"
          echo "ASG: ${{ needs.verify-infrastructure.outputs.asg_name }}"
          echo "ALB URL: ${{ needs.verify-infrastructure.outputs.alb_url }}"
          echo "=========================================="
